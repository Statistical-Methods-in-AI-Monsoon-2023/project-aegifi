params: {'units': 128, 'dropout': 0.3, 'layers': 2, 'batch_size': 512, 'epochs': 5, 'lr': 0.001}
Model: "BinaryGRU"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 250, 100)          6000000   
                                                                 
 gru (GRU)                   (None, 250, 128)          88320     
                                                                 
 dropout (Dropout)           (None, 250, 128)          0         
                                                                 
 layer_normalization (Layer  (None, 250, 128)          256       
 Normalization)                                                  
                                                                 
 gru_1 (GRU)                 (None, 128)               99072     
                                                                 
 dropout_1 (Dropout)         (None, 128)               0         
                                                                 
 layer_normalization_1 (Lay  (None, 128)               256       
 erNormalization)                                                
                                                                 
 dense (Dense)               (None, 20)                2580      
                                                                 
=================================================================
Total params: 6190484 (23.61 MB)
Trainable params: 6190484 (23.61 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Predict time: 21.762163639068604
Accuracy: 0.2650254276467869
Hamming Score: 0.9264091154261057
Jaccard Score: 0.3694916652913022
Hit Rate: 0.7271729079981507
Classification Report:
              precision    recall  f1-score   support

           0       0.54      0.36      0.43      4821
           1       0.51      0.23      0.31      3374
           2       0.69      0.44      0.53      3203
           3       0.47      0.30      0.36      2718
           4       0.65      0.62      0.64     14502
           5       0.48      0.37      0.42      3636
           6       0.69      0.71      0.70     23686
           7       0.52      0.25      0.34      4101
           8       0.44      0.22      0.29      2982
           9       0.51      0.29      0.37      2427
          10       0.60      0.60      0.60      3935
          11       0.66      0.57      0.61      2586
          12       0.45      0.12      0.19      1131
          13       0.37      0.10      0.15      2647
          14       0.44      0.22      0.29      5494
          15       0.66      0.47      0.55      2767
          16       0.73      0.53      0.62      1270
          17       0.48      0.31      0.37      5442
          18       0.59      0.41      0.48      1420
          19       0.78      0.68      0.72      1229

   micro avg       0.62      0.48      0.54     93371
   macro avg       0.56      0.39      0.45     93371
weighted avg       0.59      0.48      0.52     93371
 samples avg       0.67      0.55      0.75     93371

