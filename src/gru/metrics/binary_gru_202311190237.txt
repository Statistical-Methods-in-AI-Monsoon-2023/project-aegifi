params: {'units': 128, 'dropout': 0.3, 'layers': 2, 'batch_size': 512, 'epochs': 5, 'lr': 0.001}
Model: "BinaryGRU"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 250, 100)          6000000   
                                                                 
 gru (GRU)                   (None, 250, 128)          88320     
                                                                 
 dropout (Dropout)           (None, 250, 128)          0         
                                                                 
 layer_normalization (Layer  (None, 250, 128)          256       
 Normalization)                                                  
                                                                 
 gru_1 (GRU)                 (None, 128)               99072     
                                                                 
 dropout_1 (Dropout)         (None, 128)               0         
                                                                 
 layer_normalization_1 (Lay  (None, 128)               256       
 erNormalization)                                                
                                                                 
 dense (Dense)               (None, 20)                2580      
                                                                 
=================================================================
Total params: 6190484 (23.61 MB)
Trainable params: 6190484 (23.61 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Predict time: 21.07762122154236
Accuracy: 0.2939204808136847
Hamming Score: 0.9317007628294036
Jaccard Score: 0.35935566055634355
Hit Rate: 0.6825396825396826
Classification Report:
              precision    recall  f1-score   support

           0       0.65      0.29      0.40      4821
           1       0.58      0.16      0.25      3374
           2       0.72      0.43      0.54      3203
           3       0.62      0.14      0.23      2718
           4       0.73      0.58      0.64     14502
           5       0.58      0.24      0.34      3636
           6       0.71      0.72      0.71     23686
           7       0.66      0.17      0.28      4101
           8       0.58      0.11      0.19      2982
           9       0.56      0.25      0.35      2427
          10       0.75      0.47      0.58      3935
          11       0.76      0.52      0.62      2586
          12       0.72      0.03      0.05      1131
          13       0.50      0.01      0.03      2647
          14       0.56      0.12      0.20      5494
          15       0.70      0.46      0.56      2767
          16       0.77      0.51      0.61      1270
          17       0.60      0.14      0.22      5442
          18       0.58      0.48      0.53      1420
          19       0.84      0.66      0.74      1229

   micro avg       0.70      0.43      0.53     93371
   macro avg       0.66      0.32      0.40     93371
weighted avg       0.67      0.43      0.49     93371
 samples avg       0.75      0.50      0.72     93371

