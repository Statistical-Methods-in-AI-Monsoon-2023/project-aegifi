Loaded from binary_gru_1.keras
params: {'units': 128, 'dropout': 0.2, 'layers': 2, 'batch_size': 128, 'epochs': 5, 'lr': 0.001}
Model: "BinaryGRU"
_________________________________________________________________
 Layer (type)                Output Shape              Param #   
=================================================================
 embedding (Embedding)       (None, 250, 100)          6000000   
                                                                 
 gru (GRU)                   (None, 250, 128)          88320     
                                                                 
 dropout (Dropout)           (None, 250, 128)          0         
                                                                 
 layer_normalization (Layer  (None, 250, 128)          256       
 Normalization)                                                  
                                                                 
 gru_1 (GRU)                 (None, 128)               99072     
                                                                 
 dropout_1 (Dropout)         (None, 128)               0         
                                                                 
 layer_normalization_1 (Lay  (None, 128)               256       
 erNormalization)                                                
                                                                 
 dense (Dense)               (None, 20)                2580      
                                                                 
=================================================================
Total params: 6190484 (23.61 MB)
Trainable params: 6190484 (23.61 MB)
Non-trainable params: 0 (0.00 Byte)
_________________________________________________________________
Predict time: 218.53195786476135
Accuracy: 0.28484743411927876
Hamming Score: 0.9305584450608723
Jaccard Score: 0.38126909477875803
Hit Rate: 0.7311604253351827
Classification Report:
              precision    recall  f1-score   support

           0       0.62      0.34      0.44      4821
           1       0.52      0.29      0.37      3374
           2       0.64      0.53      0.58      3203
           3       0.56      0.27      0.37      2718
           4       0.70      0.60      0.65     14502
           5       0.53      0.36      0.43      3636
           6       0.72      0.71      0.71     23686
           7       0.53      0.30      0.38      4101
           8       0.55      0.17      0.26      2982
           9       0.54      0.29      0.38      2427
          10       0.74      0.48      0.58      3935
          11       0.66      0.62      0.64      2586
          12       0.61      0.06      0.11      1131
          13       0.45      0.08      0.14      2647
          14       0.51      0.18      0.27      5494
          15       0.65      0.53      0.59      2767
          16       0.72      0.62      0.67      1270
          17       0.53      0.27      0.36      5442
          18       0.49      0.58      0.53      1420
          19       0.81      0.69      0.74      1229

   micro avg       0.66      0.48      0.55     93371
   macro avg       0.60      0.40      0.46     93371
weighted avg       0.63      0.48      0.53     93371
 samples avg       0.71      0.55      0.75     93371

