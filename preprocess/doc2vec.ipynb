{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import random\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = '../data/preprocessed_data.csv'\n",
    "\n",
    "data = pd.read_csv(data_file, index_col=0)\n",
    "\n",
    "X = data['plot'].values\n",
    "X = X[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(X, tokens_only=False):\n",
    "    for i, line in enumerate(X):\n",
    "        tokens = gensim.utils.simple_preprocess(line)\n",
    "        if tokens_only:\n",
    "            yield tokens\n",
    "        else:\n",
    "            yield TaggedDocument(tokens, [i])\n",
    "            \n",
    "train_corpus = list(read_corpus(X))\n",
    "X_tokens = list(read_corpus(X, tokens_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 16:36:34,757 : INFO : Doc2Vec lifecycle event {'params': 'Doc2Vec<dm/m,d300,n5,w5,mc3,s0.001,t3>', 'datetime': '2023-11-20T16:36:34.757011', 'gensim': '4.3.2', 'python': '3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]', 'platform': 'Linux-4.15.0-210-generic-x86_64-with-glibc2.27', 'event': 'created'}\n",
      "2023-11-20 16:36:34,759 : INFO : collecting all words and their counts\n",
      "2023-11-20 16:36:34,760 : INFO : PROGRESS: at example #0, processed 0 words (0 words/s), 0 word types, 0 tags\n",
      "2023-11-20 16:36:34,763 : INFO : collected 2828 word types and 100 unique tags from a corpus of 100 examples and 5194 words\n",
      "2023-11-20 16:36:34,764 : INFO : Creating a fresh vocabulary\n",
      "2023-11-20 16:36:34,767 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=3 retains 471 unique words (16.65% of original 2828, drops 2357)', 'datetime': '2023-11-20T16:36:34.767497', 'gensim': '4.3.2', 'python': '3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]', 'platform': 'Linux-4.15.0-210-generic-x86_64-with-glibc2.27', 'event': 'prepare_vocab'}\n",
      "2023-11-20 16:36:34,768 : INFO : Doc2Vec lifecycle event {'msg': 'effective_min_count=3 leaves 2359 word corpus (45.42% of original 5194, drops 2835)', 'datetime': '2023-11-20T16:36:34.768376', 'gensim': '4.3.2', 'python': '3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]', 'platform': 'Linux-4.15.0-210-generic-x86_64-with-glibc2.27', 'event': 'prepare_vocab'}\n",
      "2023-11-20 16:36:34,772 : INFO : deleting the raw counts dictionary of 2828 items\n",
      "2023-11-20 16:36:34,772 : INFO : sample=0.001 downsamples 78 most-common words\n",
      "2023-11-20 16:36:34,773 : INFO : Doc2Vec lifecycle event {'msg': 'downsampling leaves estimated 2060.5188213499505 word corpus (87.3%% of prior 2359)', 'datetime': '2023-11-20T16:36:34.773556', 'gensim': '4.3.2', 'python': '3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]', 'platform': 'Linux-4.15.0-210-generic-x86_64-with-glibc2.27', 'event': 'prepare_vocab'}\n",
      "2023-11-20 16:36:34,779 : INFO : estimated required memory for 471 words and 300 dimensions: 1505900 bytes\n",
      "2023-11-20 16:36:34,779 : INFO : resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'life' appeared 25 times in the training corpus.\n"
     ]
    }
   ],
   "source": [
    "model = Doc2Vec(vector_size=300, min_count=3, epochs=40)\n",
    "model.build_vocab(train_corpus)\n",
    "print(f\"Word 'life' appeared {model.wv.get_vecattr('life', 'count')} times in the training corpus.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-20 16:36:35,051 : INFO : Doc2Vec lifecycle event {'msg': 'training model with 3 workers on 471 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2023-11-20T16:36:35.051599', 'gensim': '4.3.2', 'python': '3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]', 'platform': 'Linux-4.15.0-210-generic-x86_64-with-glibc2.27', 'event': 'train'}\n",
      "2023-11-20 16:36:35,076 : INFO : EPOCH 0: training on 5194 raw words (2159 effective words) took 0.0s, 113819 effective words/s\n",
      "2023-11-20 16:36:35,096 : INFO : EPOCH 1: training on 5194 raw words (2153 effective words) took 0.0s, 133555 effective words/s\n",
      "2023-11-20 16:36:35,120 : INFO : EPOCH 2: training on 5194 raw words (2147 effective words) took 0.0s, 104948 effective words/s\n",
      "2023-11-20 16:36:35,141 : INFO : EPOCH 3: training on 5194 raw words (2146 effective words) took 0.0s, 124424 effective words/s\n",
      "2023-11-20 16:36:35,161 : INFO : EPOCH 4: training on 5194 raw words (2180 effective words) took 0.0s, 124882 effective words/s\n",
      "2023-11-20 16:36:35,180 : INFO : EPOCH 5: training on 5194 raw words (2151 effective words) took 0.0s, 129891 effective words/s\n",
      "2023-11-20 16:36:35,201 : INFO : EPOCH 6: training on 5194 raw words (2197 effective words) took 0.0s, 124137 effective words/s\n",
      "2023-11-20 16:36:35,219 : INFO : EPOCH 7: training on 5194 raw words (2180 effective words) took 0.0s, 149750 effective words/s\n",
      "2023-11-20 16:36:35,233 : INFO : EPOCH 8: training on 5194 raw words (2160 effective words) took 0.0s, 191620 effective words/s\n",
      "2023-11-20 16:36:35,253 : INFO : EPOCH 9: training on 5194 raw words (2171 effective words) took 0.0s, 126342 effective words/s\n",
      "2023-11-20 16:36:35,271 : INFO : EPOCH 10: training on 5194 raw words (2170 effective words) took 0.0s, 147472 effective words/s\n",
      "2023-11-20 16:36:35,286 : INFO : EPOCH 11: training on 5194 raw words (2148 effective words) took 0.0s, 182081 effective words/s\n",
      "2023-11-20 16:36:35,306 : INFO : EPOCH 12: training on 5194 raw words (2174 effective words) took 0.0s, 140655 effective words/s\n",
      "2023-11-20 16:36:35,325 : INFO : EPOCH 13: training on 5194 raw words (2165 effective words) took 0.0s, 125340 effective words/s\n",
      "2023-11-20 16:36:35,343 : INFO : EPOCH 14: training on 5194 raw words (2167 effective words) took 0.0s, 145538 effective words/s\n",
      "2023-11-20 16:36:35,364 : INFO : EPOCH 15: training on 5194 raw words (2168 effective words) took 0.0s, 122297 effective words/s\n",
      "2023-11-20 16:36:35,379 : INFO : EPOCH 16: training on 5194 raw words (2162 effective words) took 0.0s, 179464 effective words/s\n",
      "2023-11-20 16:36:35,393 : INFO : EPOCH 17: training on 5194 raw words (2174 effective words) took 0.0s, 200387 effective words/s\n",
      "2023-11-20 16:36:35,408 : INFO : EPOCH 18: training on 5194 raw words (2169 effective words) took 0.0s, 192406 effective words/s\n",
      "2023-11-20 16:36:35,430 : INFO : EPOCH 19: training on 5194 raw words (2176 effective words) took 0.0s, 118309 effective words/s\n",
      "2023-11-20 16:36:35,450 : INFO : EPOCH 20: training on 5194 raw words (2153 effective words) took 0.0s, 136856 effective words/s\n",
      "2023-11-20 16:36:35,472 : INFO : EPOCH 21: training on 5194 raw words (2173 effective words) took 0.0s, 112110 effective words/s\n",
      "2023-11-20 16:36:35,494 : INFO : EPOCH 22: training on 5194 raw words (2156 effective words) took 0.0s, 119618 effective words/s\n",
      "2023-11-20 16:36:35,510 : INFO : EPOCH 23: training on 5194 raw words (2141 effective words) took 0.0s, 163646 effective words/s\n",
      "2023-11-20 16:36:35,530 : INFO : EPOCH 24: training on 5194 raw words (2152 effective words) took 0.0s, 129841 effective words/s\n",
      "2023-11-20 16:36:35,550 : INFO : EPOCH 25: training on 5194 raw words (2152 effective words) took 0.0s, 130596 effective words/s\n",
      "2023-11-20 16:36:35,569 : INFO : EPOCH 26: training on 5194 raw words (2174 effective words) took 0.0s, 136647 effective words/s\n",
      "2023-11-20 16:36:35,588 : INFO : EPOCH 27: training on 5194 raw words (2164 effective words) took 0.0s, 138861 effective words/s\n",
      "2023-11-20 16:36:35,617 : INFO : EPOCH 28: training on 5194 raw words (2168 effective words) took 0.0s, 84173 effective words/s\n",
      "2023-11-20 16:36:35,634 : INFO : EPOCH 29: training on 5194 raw words (2161 effective words) took 0.0s, 162330 effective words/s\n",
      "2023-11-20 16:36:35,647 : INFO : EPOCH 30: training on 5194 raw words (2177 effective words) took 0.0s, 225612 effective words/s\n",
      "2023-11-20 16:36:35,668 : INFO : EPOCH 31: training on 5194 raw words (2154 effective words) took 0.0s, 125977 effective words/s\n",
      "2023-11-20 16:36:35,689 : INFO : EPOCH 32: training on 5194 raw words (2147 effective words) took 0.0s, 124978 effective words/s\n",
      "2023-11-20 16:36:35,707 : INFO : EPOCH 33: training on 5194 raw words (2162 effective words) took 0.0s, 138685 effective words/s\n",
      "2023-11-20 16:36:35,729 : INFO : EPOCH 34: training on 5194 raw words (2179 effective words) took 0.0s, 116684 effective words/s\n",
      "2023-11-20 16:36:35,749 : INFO : EPOCH 35: training on 5194 raw words (2128 effective words) took 0.0s, 127496 effective words/s\n",
      "2023-11-20 16:36:35,770 : INFO : EPOCH 36: training on 5194 raw words (2154 effective words) took 0.0s, 132332 effective words/s\n",
      "2023-11-20 16:36:35,789 : INFO : EPOCH 37: training on 5194 raw words (2148 effective words) took 0.0s, 126245 effective words/s\n",
      "2023-11-20 16:36:35,808 : INFO : EPOCH 38: training on 5194 raw words (2162 effective words) took 0.0s, 144981 effective words/s\n",
      "2023-11-20 16:36:35,828 : INFO : EPOCH 39: training on 5194 raw words (2171 effective words) took 0.0s, 132097 effective words/s\n",
      "2023-11-20 16:36:35,829 : INFO : Doc2Vec lifecycle event {'msg': 'training on 207760 raw words (86493 effective words) took 0.8s, 111582 effective words/s', 'datetime': '2023-11-20T16:36:35.829160', 'gensim': '4.3.2', 'python': '3.10.13 | packaged by conda-forge | (main, Oct 26 2023, 18:07:37) [GCC 12.3.0]', 'platform': 'Linux-4.15.0-210-generic-x86_64-with-glibc2.27', 'event': 'train'}\n"
     ]
    }
   ],
   "source": [
    "model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 (300,)\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "# vector = model.infer_vector(X)\n",
    "for i in tqdm(X_tokens):\n",
    "    embeddings.append(model.infer_vector(i))\n",
    "print(len(embeddings), embeddings[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
